{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4654321",
   "metadata": {},
   "source": [
    "## Web Scraping â€¢ Private APIs â€¢ Selenium â€¢ JSON â€¢ Pandas â€¢ Data Cleaning\n",
    "\n",
    "---\n",
    "\n",
    "## 1ï¸âƒ£ WEBSITE ACCESS & HTTP REQUESTS\n",
    "\n",
    "### ğŸ”¹ Library\n",
    "```python\n",
    "import requests\n",
    "Explanation\n",
    "requests is a Python library used to send HTTP requests (GET, POST, etc.) and receive responses from web servers.\n",
    "\n",
    "ğŸ”¹ Core method\n",
    "requests.get(url, headers=headers)\n",
    "Explanation\n",
    "\n",
    "Sends an HTTP GET request to the server\n",
    "\n",
    "Returns a Response object containing status code, headers, and data\n",
    "\n",
    "ğŸ”¹ Why headers are required\n",
    "Avoid 403 Forbidden\n",
    "\n",
    "Mimic real browser behavior\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "}\n",
    "Explanation\n",
    "Many websites block requests that donâ€™t look like they come from a real browser.\n",
    "User-Agent tells the server who you are pretending to be.\n",
    "\n",
    "2ï¸âƒ£ BEAUTIFULSOUP (HTML PARSING)\n",
    "ğŸ”¹ Correct import\n",
    "from bs4 import BeautifulSoup\n",
    "âŒ Wrong\n",
    "\n",
    "import bs4 as BeautifulSoup\n",
    "Explanation\n",
    "\n",
    "BeautifulSoup is a class, not a module\n",
    "\n",
    "Wrong import causes: TypeError: 'module' object is not callable\n",
    "\n",
    "ğŸ”¹ Create soup object\n",
    "soup = BeautifulSoup(response.text, \"lxml\")\n",
    "Explanation\n",
    "\n",
    "response.text â†’ raw HTML\n",
    "\n",
    "\"lxml\" â†’ fast HTML parser\n",
    "\n",
    "ğŸ”¹ Errors encountered & meaning\n",
    "Error\tMeaning\n",
    "module not callable\tWrong import\n",
    "FeatureNotFound: lxml\tParser not installed\n",
    "Akamai error page\tBot protection\n",
    "ğŸ“Œ Conclusion:\n",
    "HTML scraping alone is unreliable for modern, JS-heavy websites.\n",
    "\n",
    "3ï¸âƒ£ NETWORK TAB â†’ API DISCOVERY\n",
    "ğŸ”¹ Tools\n",
    "Chrome DevTools â†’ Network\n",
    "\n",
    "Filter: Fetch / XHR\n",
    "\n",
    "ğŸ”¹ What you inspected\n",
    "Request URL\n",
    "\n",
    "Headers\n",
    "\n",
    "Cookies\n",
    "\n",
    "Payload\n",
    "\n",
    "HTTP Method (POST)\n",
    "\n",
    "ğŸ”¹ Result\n",
    "You discovered a private JSON API endpoint:\n",
    "\n",
    "/servicegateway-ambitionbox/company-services/...\n",
    "Explanation\n",
    "Modern websites load data via APIs, not HTML.\n",
    "Network tab lets you reverse-engineer those APIs.\n",
    "\n",
    "4ï¸âƒ£ WHY DIRECT API CALLS FAIL (403)\n",
    "ğŸ”¹ Cause\n",
    "Missing:\n",
    "\n",
    "Cookies\n",
    "\n",
    "System headers\n",
    "\n",
    "Browser session\n",
    "\n",
    "ğŸ”¹ Why pd.read_json(url) failed\n",
    "It cannot send:\n",
    "\n",
    "Headers\n",
    "\n",
    "POST payload\n",
    "\n",
    "Cookies\n",
    "\n",
    "Explanation\n",
    "pd.read_json() only works for open public APIs, not protected ones.\n",
    "\n",
    "5ï¸âƒ£ SELENIUM â€” WHY & WHEN IT IS USED\n",
    "ğŸ”¹ Why Selenium is needed\n",
    "Execute JavaScript\n",
    "\n",
    "Create a trusted browser session\n",
    "\n",
    "Generate valid cookies\n",
    "\n",
    "Bypass bot detection\n",
    "\n",
    "ğŸ”¹ Library\n",
    "from selenium import webdriver\n",
    "Explanation\n",
    "Selenium controls a real browser, so the website trusts it.\n",
    "\n",
    "6ï¸âƒ£ SELENIUM WORKFLOW (ALGORITHM)\n",
    "Launch browser\n",
    "\n",
    "Open target website\n",
    "\n",
    "Let JavaScript load\n",
    "\n",
    "Extract cookies\n",
    "\n",
    "Transfer cookies to requests.Session\n",
    "\n",
    "Call private API\n",
    "\n",
    "7ï¸âƒ£ SELENIUM CODE (CORE CONCEPTS)\n",
    "ğŸ”¹ Launch browser\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.ambitionbox.com/list-of-companies?page=1\")\n",
    "Explanation\n",
    "\n",
    "Opens Chrome\n",
    "\n",
    "Loads JS\n",
    "\n",
    "Generates session cookies\n",
    "\n",
    "ğŸ”¹ Extract cookies\n",
    "cookies = driver.get_cookies()\n",
    "Each cookie is a dictionary:\n",
    "\n",
    "{\n",
    "  'name': 'PHPSESSID',\n",
    "  'value': 'abc123',\n",
    "  'domain': '.ambitionbox.com'\n",
    "}\n",
    "Explanation\n",
    "Cookies prove to the server that your request comes from a valid browser session.\n",
    "\n",
    "8ï¸âƒ£ TRANSFERRING COOKIES TO REQUESTS\n",
    "ğŸ”¹ Create session\n",
    "session = requests.Session()\n",
    "Explanation\n",
    "A Session persists:\n",
    "\n",
    "Cookies\n",
    "\n",
    "Headers\n",
    "\n",
    "Authentication\n",
    "\n",
    "ğŸ”¹ Add cookies\n",
    "for cookie in cookies:\n",
    "    session.cookies.set(cookie['name'], cookie['value'])\n",
    "Explanation\n",
    "Transfers Seleniumâ€™s browser identity into requests.\n",
    "\n",
    "ğŸ”¹ Set headers\n",
    "session.headers.update({\n",
    "    \"User-Agent\": \"Mozilla/5.0\",\n",
    "    \"Referer\": \"https://www.ambitionbox.com/\"\n",
    "})\n",
    "ğŸ“Œ Result:\n",
    "Requests now behaves exactly like Seleniumâ€™s browser.\n",
    "\n",
    "9ï¸âƒ£ CALLING PRIVATE API (POST REQUEST)\n",
    "payload = {\n",
    "    \"page\": 1,\n",
    "    \"sortBy\": \"popular\",\n",
    "    \"limit\": 20\n",
    "}\n",
    "\n",
    "response = session.post(api_url, json=payload)\n",
    "data = response.json()\n",
    "Explanation\n",
    "\n",
    "post() â†’ sends data to server\n",
    "\n",
    "json=payload â†’ auto JSON encoding\n",
    "\n",
    ".json() â†’ converts response into Python dict/list\n",
    "\n",
    "ğŸ”Ÿ JSON STRUCTURE ANALYSIS\n",
    "ğŸ”¹ Inspect JSON\n",
    "data.keys()\n",
    "type(data)\n",
    "Explanation\n",
    "Always inspect structure before indexing.\n",
    "\n",
    "ğŸ”¹ Common mistake\n",
    "data[\"cards\"][\"companies\"]  # âŒ\n",
    "Why wrong?\n",
    "cards is a list, not a dictionary.\n",
    "\n",
    "ğŸ”¹ Correct approach\n",
    "type(data[\"cards\"])\n",
    "data[\"cards\"][0].keys()\n",
    "Key lesson:\n",
    "ğŸ‘‰ Lists â†’ index with numbers\n",
    "ğŸ‘‰ Dicts â†’ index with keys\n",
    "\n",
    "1ï¸âƒ£1ï¸âƒ£ PANDAS DATAFRAME CREATION\n",
    "ğŸ”¹ Create DataFrame\n",
    "df = pd.DataFrame(companies)\n",
    "Explanation\n",
    "\n",
    "Converts list of dictionaries into tabular form\n",
    "\n",
    "Keys â†’ columns\n",
    "\n",
    "ğŸ”¹ Inspect\n",
    "df.head()\n",
    "df.info()\n",
    "df.columns\n",
    "Method\tPurpose\n",
    "head()\tPreview rows\n",
    "info()\tData types & nulls\n",
    "columns\tColumn names\n",
    "1ï¸âƒ£2ï¸âƒ£ ACCESSING NESTED DATA IN COLUMNS\n",
    "ğŸ”¹ Safe extraction pattern\n",
    "df['column'] = df['column'].apply(\n",
    "    lambda x: x.get('name') if isinstance(x, dict) else None\n",
    ")\n",
    "ğŸ”¹ Concept explanations\n",
    "apply() â†’ applies function to each row\n",
    "\n",
    "lambda â†’ anonymous function\n",
    "\n",
    "isinstance() â†’ type safety\n",
    "\n",
    ".get() â†’ avoids KeyError\n",
    "\n",
    "1ï¸âƒ£3ï¸âƒ£ DEALING WITH NUMERIC None VALUES FROM API\n",
    "ğŸ”¹ Convert safely\n",
    "df['col'] = pd.to_numeric(df['col'], errors='coerce')\n",
    "Explanation\n",
    "\n",
    "Converts invalid values to NaN\n",
    "\n",
    "Prevents crashes\n",
    "\n",
    "ğŸ”¹ Handling strategies\n",
    "Data Type\tStrategy\n",
    "Counts\tFill with 0\n",
    "Ratings\tMedian\n",
    "Salaries\tMedian or keep NaN\n",
    "ML\tMissing-value flag\n",
    "df['minCtc_missing'] = df['minCtc'].isna().astype(int)\n",
    "1ï¸âƒ£4ï¸âƒ£ IMPORTANT METHODS & FUNCTIONS USED\n",
    "ğŸ§° Python\n",
    "type() â†’ object type\n",
    "\n",
    "isinstance() â†’ type checking\n",
    "\n",
    "len() â†’ length\n",
    "\n",
    "iter() / next() â†’ iteration\n",
    "\n",
    "ğŸ§° Requests\n",
    "get() â†’ fetch data\n",
    "\n",
    "post() â†’ send data\n",
    "\n",
    "Session() â†’ persistent state\n",
    "\n",
    "headers.update() â†’ browser identity\n",
    "\n",
    "ğŸ§° Selenium\n",
    "webdriver.Chrome() â†’ browser\n",
    "\n",
    "driver.get() â†’ load page\n",
    "\n",
    "driver.get_cookies() â†’ extract session\n",
    "\n",
    "ğŸ§° Pandas\n",
    "DataFrame() â†’ table creation\n",
    "\n",
    "apply() â†’ row-wise logic\n",
    "\n",
    "fillna() â†’ missing values\n",
    "\n",
    "astype() â†’ type conversion\n",
    "\n",
    "to_numeric() â†’ safe numeric casting\n",
    "\n",
    "isna() â†’ missing detection\n",
    "\n",
    "head() / info() â†’ inspection\n",
    "\n",
    "ğŸ§  FINAL PIPELINE (MENTAL MODEL)\n",
    "Website\n",
    "   â†“\n",
    "Selenium (browser session)\n",
    "   â†“\n",
    "Cookies + Headers\n",
    "   â†“\n",
    "Requests Session\n",
    "   â†“\n",
    "Private API (JSON)\n",
    "   â†“\n",
    "Pandas DataFrame\n",
    "   â†“\n",
    "Cleaning & Transformation\n",
    "   â†“\n",
    "ML / Analysis Ready Data\n",
    "ğŸ¯ WHAT YOU ACTUALLY LEARNED (BIG PICTURE)\n",
    "âœ” Modern scraping â‰  HTML\n",
    "âœ” APIs are hidden but discoverable\n",
    "âœ” Selenium is for session trust, not scraping\n",
    "âœ” JSON â‰  always dict (lists matter!)\n",
    "âœ” Pandas requires defensive coding\n",
    "âœ” Missing data must be treated semantically"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
