{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58b66ef8",
   "metadata": {},
   "source": [
    "# ğŸ“Œ What is Feature Scaling?\n",
    "\n",
    "**Feature Scaling** is a data preprocessing technique used to bring all input features (variables) to a similar range or scale.\n",
    "\n",
    "It is mainly used in **Machine Learning** when features have different units or magnitudes.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Why Feature Scaling is Needed?\n",
    "\n",
    "Imagine this dataset:\n",
    "\n",
    "| Age (years) | Salary (â‚¹) |\n",
    "|-------------|------------|\n",
    "| 25          | 250000     |\n",
    "| 30          | 500000     |\n",
    "| 35          | 750000     |\n",
    "\n",
    "- **Age** range â†’ 25 to 35  \n",
    "- **Salary** range â†’ 2,50,000 to 7,50,000  \n",
    "\n",
    "Clearly, salary values are much larger than age.\n",
    "\n",
    "If we apply algorithms like:\n",
    "\n",
    "- KNN\n",
    "- K-Means\n",
    "- SVM\n",
    "- Linear Regression (Gradient Descent)\n",
    "- Neural Networks\n",
    "\n",
    "The model may give **more importance to Salary** because its magnitude is larger.\n",
    "\n",
    "ğŸ‘‰ Feature scaling ensures **equal importance** to all features.\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ”¥ Types of Feature Scaling\n",
    "\n",
    "There are mainly **2 important methods**:\n",
    "\n",
    "---\n",
    "\n",
    "# 1ï¸âƒ£ Min-Max Scaling (Normalization)\n",
    "\n",
    "### ğŸ“Œ Formula:\n",
    "\n",
    "X_scaled = (X - X_min) / (X_max - X_min)\n",
    "\n",
    "It scales data between **0 and 1**.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Example\n",
    "\n",
    "Suppose:\n",
    "\n",
    "Age values = 25, 30, 35  \n",
    "\n",
    "Here:\n",
    "- Min = 25  \n",
    "- Max = 35  \n",
    "\n",
    "For Age = 30:\n",
    "\n",
    "(30 - 25) / (35 - 25) = 5 / 10 = 0.5\n",
    "\n",
    "Scaled values:\n",
    "\n",
    "| Original Age | Scaled Age |\n",
    "|--------------|------------|\n",
    "| 25           | 0.0        |\n",
    "| 30           | 0.5        |\n",
    "| 35           | 1.0        |\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“Œ When to Use?\n",
    "\n",
    "- When data does not contain many outliers\n",
    "- When we need bounded values (like neural networks)\n",
    "\n",
    "---\n",
    "\n",
    "# 2ï¸âƒ£ Standardization (Z-Score Scaling)\n",
    "\n",
    "Also called **Standard Scaling**.\n",
    "\n",
    "### ğŸ“Œ Formula:\n",
    "\n",
    "X_scaled = (X - Î¼) / Ïƒ\n",
    "\n",
    "Where:\n",
    "- Î¼ = mean\n",
    "- Ïƒ = standard deviation\n",
    "\n",
    "It transforms data so that:\n",
    "- Mean = 0\n",
    "- Standard deviation = 1\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Example\n",
    "\n",
    "Suppose Age values:\n",
    "\n",
    "25, 30, 35  \n",
    "\n",
    "Mean = 30  \n",
    "Std deviation â‰ˆ 4.08  \n",
    "\n",
    "For Age = 35:\n",
    "\n",
    "(35 - 30) / 4.08 â‰ˆ 1.22\n",
    "\n",
    "So scaled value â‰ˆ 1.22\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“Œ When to Use?\n",
    "\n",
    "- When data has outliers\n",
    "- When algorithm assumes normal distribution\n",
    "- Best for:\n",
    "  - Linear Regression\n",
    "  - Logistic Regression\n",
    "  - SVM\n",
    "  - PCA\n",
    "\n",
    "---\n",
    "\n",
    "# âš ï¸ When Feature Scaling is NOT Required\n",
    "\n",
    "You **donâ€™t need scaling** in:\n",
    "\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "- LightGBM\n",
    "\n",
    "Because tree-based models split based on feature importance, not distance.\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ§  Why Scaling Helps (Mathematical Intuition)\n",
    "\n",
    "Suppose we calculate Euclidean distance in KNN:\n",
    "\n",
    "Distance = âˆš((xâ‚ - yâ‚)Â² + (xâ‚‚ - yâ‚‚)Â²)\n",
    "\n",
    "If one feature has very large values, it will dominate the distance calculation.\n",
    "\n",
    "Scaling prevents this dominance.\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ’» Python Example\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'Age': [25, 30, 35],\n",
    "    'Salary': [250000, 500000, 750000]\n",
    "})\n",
    "\n",
    "# Min-Max Scaling\n",
    "minmax = MinMaxScaler()\n",
    "scaled_minmax = minmax.fit_transform(data)\n",
    "\n",
    "# Standard Scaling\n",
    "standard = StandardScaler()\n",
    "scaled_standard = standard.fit_transform(data)\n",
    "\n",
    "print(\"Min-Max Scaled:\\n\", scaled_minmax)\n",
    "print(\"\\nStandard Scaled:\\n\", scaled_standard)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ” Comparison\n",
    "\n",
    "| Method | Range | Affected by Outliers? | Best For |\n",
    "|--------|-------|----------------------|----------|\n",
    "| Min-Max | 0 to 1 | Yes | Neural Networks |\n",
    "| Standardization | Mean=0, Std=1 | Less | Linear Models, SVM |\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸš€ Final Understanding\n",
    "\n",
    "Feature Scaling:\n",
    "\n",
    "âœ” Makes training faster  \n",
    "âœ” Prevents bias toward large features  \n",
    "âœ” Improves convergence of gradient descent  \n",
    "âœ” Essential for distance-based models  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a50a4e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
